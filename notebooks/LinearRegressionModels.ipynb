{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models: OLS Linear Regression, Ridge Regression, Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "# from utilities import cross_val_metrics_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_absolute_percentage_error(y_true, y_pred):\n",
    "  result = abs(y_true - y_pred) / y_true\n",
    "  return result.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, root_mean_squared_error, median_absolute_error, mean_absolute_percentage_error, accuracy_score, precision_score, recall_score, f1_score\n",
    "from pandas import DataFrame, Series\n",
    "def cross_val_metrics_calculate(model, X:DataFrame, y:Series, splits, metrics=['mse', 'rmse', 'mae', 'mape', 'medae', 'medape']):\n",
    "    n_folds = 0\n",
    "    result = {name:0 for name in metrics}\n",
    "    for train_index, test_index in splits:\n",
    "        n_folds += 1\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        if 'mse' in metrics:\n",
    "            result['mse'] += mean_squared_error(y_test, y_pred)\n",
    "        if 'rmse' in metrics:\n",
    "            result['rmse'] += root_mean_squared_error(y_test, y_pred)\n",
    "        if 'mae' in metrics:\n",
    "            result['mae'] += mean_absolute_error(y_test, y_pred)\n",
    "        if 'mape' in metrics:\n",
    "            result['mape'] += mean_absolute_percentage_error(y_test, y_pred)\n",
    "        if 'accuracy' in metrics:\n",
    "            result['accuracy'] += accuracy_score(y_test, y_pred)\n",
    "        if 'precision' in metrics:\n",
    "            result['precision'] += precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        if 'recall' in metrics:\n",
    "            result['recall'] += recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        if 'f1' in metrics:\n",
    "            result['f1'] += f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
    "        if 'medae' in metrics:\n",
    "            result['medae'] += median_absolute_error(y_test, y_pred)\n",
    "        if 'medape' in metrics:\n",
    "            result['medape'] += median_absolute_percentage_error(y_test, y_pred)\n",
    "    for metric in metrics:\n",
    "        result[metric] /= n_folds\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/train_data_2nd.csv\")\n",
    "X = data.iloc[:, 1:-1] # remove index column (not read by pandas as indices?)\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Area (m2)', 'Property Type', 'Bedrooms', 'Bathrooms', 'Address',\n",
       "       'Law Document', 'Quarter', 'Year', 'Latitude', 'Longitude',\n",
       "       'Postal Code', 'Importance', 'Place Rank', 'City'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = X.columns\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "kfold = KFold(n_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Linear Regresison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 19016.64659590109, 'rmse': 79.90874796632568, 'mae': 8.972131741802396, 'mape': 3.2385168596430063, 'medae': 4.545275997365727, 'medape': 0.7432247988298927}\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(lr, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0000003972\n",
      "Property Type: 1.8701870470\n",
      "Bedrooms: 1.2339251888\n",
      "Bathrooms: 0.5317770477\n",
      "Address: -0.0000345431\n",
      "Law Document: -0.7078823375\n",
      "Quarter: 0.8369317418\n",
      "Year: 2.2741343499\n",
      "Latitude: -0.6181603787\n",
      "Longitude: -0.0783127077\n",
      "Postal Code: -0.0000539938\n",
      "Importance: 5.2315554653\n",
      "Place Rank: 0.6088397524\n",
      "City: 6.0078190460\n"
     ]
    }
   ],
   "source": [
    "# Check feature importance through coefficients\n",
    "lr.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(lr.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (lr.feature_names_in_[i],lr.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- City has high coefficient as it only gets 2 values: 0 and 1 for HN and HCMC, should ignore\n",
    "- Year, property type & num. of bedrooms; Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With standardize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 19016.646595901762, 'rmse': 79.90874796632674, 'mae': 8.972131741802269, 'mape': 3.238516859642897, 'medae': 4.545275997365263, 'medape': 0.7432247988298}\n"
     ]
    }
   ],
   "source": [
    "lr_with_standardize = make_pipeline(StandardScaler(), lr)\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(lr_with_standardize, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0233702667\n",
      "Property Type: 2.6056100965\n",
      "Bedrooms: 3.4921102582\n",
      "Bathrooms: 1.3887746780\n",
      "Address: -0.0672583797\n",
      "Law Document: -0.9201180132\n",
      "Quarter: 0.8619879178\n",
      "Year: 3.4003806859\n",
      "Latitude: -2.9731446239\n",
      "Longitude: -0.4629818853\n",
      "Postal Code: -1.5270823366\n",
      "Importance: 0.2591036951\n",
      "Place Rank: 1.3504607094\n",
      "City: 2.5645609597\n"
     ]
    }
   ],
   "source": [
    "lr_with_standardize.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(lr.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (feature_names[i], lr.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Latitude has more importance to price, due to dataset consisting of real estates at HN and HCMC which have noticeably different latitudes\n",
    "- with standardized data, area has more contribution to price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No significant difference in metrics whether data is standardized or not\n",
    "- RMSE and MAE show huge average errors, but MAPE shows only 3.14% loss?\n",
    "- Time (year and quarter), property type, location features (city, latitude, postal code) and bedroom num. have high impact on price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select parameters\n",
    "ridge_cv = RidgeCV(alphas=[0.1, 0.01, 0.001, 0.005, 0.05, 0.5, 0.0025, 0.025, 0.25, 1, 2.5, 5, 10],\n",
    "                   scoring='neg_mean_absolute_error',\n",
    "                   cv=5)\n",
    "\n",
    "ridge_cv.fit(X, y)\n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv_standardize = make_pipeline(StandardScaler(), ridge_cv)\n",
    "\n",
    "ridge_cv_standardize.fit(X,y)\n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 19013.768244523155, 'rmse': 79.9040088979126, 'mae': 8.971763497115978, 'mape': 3.238188158926131, 'medae': 4.546524884464401, 'medape': 0.7445116553600659}\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10)\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(ridge, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0000004139\n",
      "Property Type: 1.8714108956\n",
      "Bedrooms: 1.2342593413\n",
      "Bathrooms: 0.5318908765\n",
      "Address: -0.0000342230\n",
      "Law Document: -0.7092743496\n",
      "Quarter: 0.8362379541\n",
      "Year: 2.2739671471\n",
      "Latitude: -0.6159401868\n",
      "Longitude: -0.0780961782\n",
      "Postal Code: -0.0000541674\n",
      "Importance: 4.3518363981\n",
      "Place Rank: 0.5981853895\n",
      "City: 5.9664079953\n"
     ]
    }
   ],
   "source": [
    "ridge.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(ridge.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (feature_names[i], ridge.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With standardize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 19001.71609043715, 'rmse': 79.88420721202944, 'mae': 8.971390695121217, 'mape': 3.2386693593554683, 'medae': 4.543566892223657, 'medape': 0.7434995342679571}\n"
     ]
    }
   ],
   "source": [
    "ridge_s = Ridge(alpha=10)\n",
    "ridge_with_standardize = make_pipeline(StandardScaler(), ridge_s)\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(ridge_with_standardize, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0233852824\n",
      "Property Type: 2.6047439077\n",
      "Bedrooms: 3.4901717669\n",
      "Bathrooms: 1.3906924428\n",
      "Address: -0.0671420499\n",
      "Law Document: -0.9207184217\n",
      "Quarter: 0.8612884301\n",
      "Year: 3.3987672259\n",
      "Latitude: -2.9493007493\n",
      "Longitude: -0.4594834600\n",
      "Postal Code: -1.5101863830\n",
      "Importance: 0.2590759337\n",
      "Place Rank: 1.3471811709\n",
      "City: 2.5578403527\n"
     ]
    }
   ],
   "source": [
    "ridge_with_standardize.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(ridge_s.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (feature_names[i], ridge_s.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge provides almost similar results (coefficients and metrics' results) to OLS linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select parameters\n",
    "lasso_cv = LassoCV(n_alphas=100,\n",
    "                   alphas=[0.1, 0.01, 0.001, 0.005, 0.05, 0.5, 0.0025, 0.025, 0.25, 1, 2.5, 5, 10],\n",
    "                   cv=None)\n",
    "\n",
    "lasso_cv.fit(X, y)\n",
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_standardize = make_pipeline(StandardScaler(), lasso_cv)\n",
    "\n",
    "lasso_cv_standardize.fit(X,y)\n",
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 19008.312878635214, 'rmse': 79.8956963196177, 'mae': 8.97105879884, 'mape': 3.238413514180036, 'medae': 4.539586791895326, 'medape': 0.7466637228201058}\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.01)\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(lasso, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0000004959\n",
      "Property Type: 1.8724589291\n",
      "Bedrooms: 1.2357145027\n",
      "Bathrooms: 0.5317423261\n",
      "Address: -0.0000321686\n",
      "Law Document: -0.7088079211\n",
      "Quarter: 0.8247430152\n",
      "Year: 2.2695205031\n",
      "Latitude: -0.6021371304\n",
      "Longitude: -0.0762069336\n",
      "Postal Code: -0.0000542255\n",
      "Importance: 0.0000000000\n",
      "Place Rank: 0.5415563853\n",
      "City: 5.7993527302\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(lasso.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (feature_names[i], lasso.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With standardize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 18534.27078426646, 'rmse': 79.11256183363977, 'mae': 8.954101480570717, 'mape': 3.2442162989717884, 'medae': 4.535761514307711, 'medape': 0.7474921237681549}\n"
     ]
    }
   ],
   "source": [
    "lasso_s = Lasso(alpha=0.025)\n",
    "lasso_with_standardize = make_pipeline(StandardScaler(), lasso_s)\n",
    "\n",
    "cv_results = cross_val_metrics_calculate(lasso_with_standardize, X, y, kfold.split(X))\n",
    "print(cv_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE: Ridge and OLS (both with and without standardization) and Lasso without standardization ~ 19000; with standardization ~ 18500\n",
    "- Small change: MAE better, MAPE worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of each feature:\n",
      "Area (m2): 0.0000000000\n",
      "Property Type: 2.5808152311\n",
      "Bedrooms: 3.4865549563\n",
      "Bathrooms: 1.3939165325\n",
      "Address: -0.0398882575\n",
      "Law Document: -0.9192615343\n",
      "Quarter: 0.8228822271\n",
      "Year: 3.3601097165\n",
      "Latitude: -2.2014596042\n",
      "Longitude: -0.3302537720\n",
      "Postal Code: -0.9519989211\n",
      "Importance: 0.2195174479\n",
      "Place Rank: 1.2114204117\n",
      "City: 2.3779500840\n"
     ]
    }
   ],
   "source": [
    "lasso_with_standardize.fit(X, y)\n",
    "print(\"Coefficients of each feature:\")\n",
    "for i in range(lasso_s.n_features_in_):\n",
    "    print(\"%s: %.10f\" % (feature_names[i], lasso_s.coef_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Lasso with data standardization performs the best, although not too different from others\n",
    "- Select different coefficient for regularization term used for standardized data provides better results; Ridge still the same but Lasso noticeably better\n",
    "- Ridge and Lasso do not really improve performance\n",
    "- Pattern in feature coefficients:\n",
    "    + property type, bedroom num., post year, and regional features (city and latitude+longitude) contribute the most; especially city and latitude, signaling a noticeable price difference in real estates at HN and HCMC\n",
    "    + area has small value of coefficient, only noticeable after standardization. This may be due to areas having large values while prices measured in billion VND are smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a version of model fitted on training set for use of comparison on testing set\n",
    "# Use model with standard scaler (better results)\n",
    "\n",
    "lr_with_standardize.fit(X, y)\n",
    "ridge_with_standardize.fit(X, y)\n",
    "lasso_with_standardize.fit(X, y)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(lr_with_standardize, open(\"../models/LinearRegression.h5\", 'wb'))\n",
    "pickle.dump(ridge_with_standardize, open(\"../models/Ridge.h5\", 'wb'))\n",
    "pickle.dump(lasso_with_standardize, open(\"../models/Lasso.h5\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
